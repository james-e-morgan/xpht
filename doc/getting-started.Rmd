---
title: "Computing with the Extended Persistent Homology Transform"
author: "James Morgan"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{getting-started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  cache = FALSE,
  verbose = TRUE,
  collapse = TRUE,
  comment = "#>"
)
```

**XPHT** provides a method for computing shape statistics of binary images through extended persistent homology. Details on the mathematics behind this can be found in [Turner, Robins, & Morgan](https://arxiv.org/abs/2208.14583).

# Extracting Boundary Contours of Binary Images
**XPHT** offers two methods for boundary curve extraction - one for a single image and one for multiple images. The main difference is that extracting the boundary of a single image has an extra step.

## Extracting Boundary Contours of a Single Binary Image
The first step in using **XPHT** is extracting the boundary curves from one or more binary images. We provide a method for doing this to a single image along with a method for doing this for all images of a particular file type or file name pattern in a specified directory. When loading a single image we need to load this in through the [Imager package](https://cran.r-project.org/package=imager). For information about the installation of Imager please refer to its Getting Started vignette.

Let's work through an example of loading a single image and extracting its boundary.

Provided with this package are two data sets of images - one of the letter **A** and one of the letter **g** - with each comprised of 95 different standard font samples. We can look at the full collection of each font using the Imager package:

```{r dev='jpeg'}
library(imager)
gridA <- system.file("extdata/gridA.png", package = "XPHT")
gridg <- system.file("extdata/gridg.png", package = "XPHT")
imgA <- load.image(gridA)
imgg <- load.image(gridg)
par(mfrow = c(1, 2))
plot(imgA, axes = FALSE)
plot(imgg, axes = FALSE)
```

Each letter **A** on the left grid is included as an individual file, as is each **g** on the right grid. The pixel values are either 0 (for black) or 1 (for white) - *this is a requirement for images used with this package* so that we can clearly define if a pixel is black or white. One of the included fonts is *courier-new*. Let's load the image for the letter **A** in and have a look at it:

```{r}
fpath <- system.file("extdata/letterA/courier-new.png", package = "XPHT")
img <- load.image(fpath)
plot(img)
```

There are two boundary curves on this image: one tracing around the outside of the letter and another tracing around the hole. When we extract the boundary curves we should expect collections of points returned to us. We do this as:

```{r}
library(XPHT)
boundaryA <- extractBoundary(img)
```

By default, this function is fairly verbose as the process of extracting boundary curves contains several steps. The main output we care about is how many curves were extracted. We can see that this is 2 which is exactly what we expected. It's also telling us that one curve was oriented anticlockwise and the other was oriented clockwise. Why should this matter? When computing the extended persistent homology we need some assumptions about where the foreground and background are. Our curves are set up so that the foreground is always on the left. If we look at the image we can see that the exterior boundary should be oriented anticlockwise and the interior boundary should be oriented clockwise in order for this to be true.

How are the boundaries stored? We can check this:

```{r}
class(boundaryA)
```

We structure our list so that the first entry tells us the number of anticlockwise curves and the number of clockwise curves. We then store all of the anticlockwise curves followed by all of the clockwise curves as matrices of their $(x,y)$ coordinates. To check this, we can plot each curve and add an arrow to a point near the start or end.
```{r}
par(mfrow = c(1, 2))
plot(boundaryA[[2]], axes = FALSE, type = "l")
arrows(x0 = boundaryA[[2]][1, 1], y0 = boundaryA[[2]][1, 2],
       x1 = boundaryA[[2]][50, 1], y1 = boundaryA[[2]][50, 2],
       col = "blue")
plot(boundaryA[[3]], axes = FALSE, type = "l")
arrows(x0 = boundaryA[[3]][1, 1], y0 = boundaryA[[3]][1, 2],
       x1 = boundaryA[[3]][20, 1], y1 = boundaryA[[3]][20, 2],
       col = "blue")
```

The arrow on each curve is set to point to a point in the first half of the curve. Following the shortest path from the start to the end of the arrow, we can check that each curve is oriented as we expect. 

We can do the exact same thing for the letter **g** in the same font. This time we don't want `extractBoundary` to print information so we set `verbose=FALSE`.
```{r}
fpath <- system.file("extdata/letterg/courier-new.png", package = "XPHT")
img <- load.image(fpath)
plot(img)
```

```{r}
boundaryg <- extractBoundary(img, verbose = FALSE)
par(mfrow = c(1, 2))
plot(boundaryg[[2]], axes = FALSE, type = "l")
arrows(x0 = boundaryg[[2]][1, 1], y0 = boundaryg[[2]][1, 2],
       x1 = boundaryg[[2]][50, 1], y1 = boundaryg[[2]][50, 2],
       col = "blue")
plot(boundaryg[[3]], axes = FALSE, type = "l")
arrows(x0 = boundaryg[[3]][1, 1], y0 = boundaryg[[3]][1, 2],
       x1 = boundaryg[[3]][20, 1], y1 = boundaryg[[3]][20, 2],
       col = "blue")
```

Once again we can see that the curves are oriented as we expect.

## Extracting Boundary Contours of Multiple Binary Images
When extracting the boundary curves of a single image, the user must first load the image into R. For multiple images, all that is needed is a directory containing the images along with the file extension. We're going to extract the boundaries of all 95 letter A images. These are `png` files with this specified. Take note that we specify this as `png` and not `.png`. It may be a good idea to set `verbose=FALSE` for this as we get output for every image processed.

```{r}
fpath <- system.file("extdata/letterA", package = "XPHT")
ABoundaries <- multiExtractBoundary(fpath, imgType = "png", verbose = FALSE)
length(ABoundaries[1:10])
class(ABoundaries)
```

Once again we store the output as a list. Each entry of this list corresponds to one image and stores the boundary curve information exactly as it did for a single image. We can plot one of these to see this.

```{r}
testBoundary <- ABoundaries[[10]]
par(mfrow = c(1, 2))
plot(testBoundary[[2]], axes = FALSE, type = "l")
arrows(x0 = testBoundary[[2]][1, 1], y0 = testBoundary[[2]][1, 2],
       x1 = testBoundary[[2]][50, 1], y1 = testBoundary[[2]][50, 2],
       col = "blue")
plot(testBoundary[[3]], axes = FALSE, type = "l")
arrows(x0 = testBoundary[[3]][1, 1], y0 = testBoundary[[3]][1, 2],
       x1 = testBoundary[[3]][20, 1], y1 = testBoundary[[3]][20, 2],
       col = "blue")
```

## Additional Options for Boundary Extraction
Both functions `extractBoundary` and `multiExtractBoundary` have a few additional options. The examples provided here have a white background (pixel value 1) and a black foreground (pixel value 0). If you want to use an image that has this reversed, then you can specify `background = 0`. 
As the computation time increases fairly quickly as the number of pixels increases we provide options to save the output of these functions for future use. If only extracting the boundary curves of a single image, then you can specify the file name. For multiple images, the file name of each output will be set to match the name of the image file.

# Computing and Plotting the Extended Persistent Homology Transform
With the boundary curves extracted, we can move on to computing the extended persistent homology transform (XPHT). In order to compute this we make one assumption about how the boundary curves are stored: if an image has $k$ anticlockwise curves and $\ell$ clockwise curves, then each curve is stored as an $n\times 2$ matrix of points ordered in the appropriate direction; the curves are stored in a list where the first entry is a vector $(k,\ell)$, the next $k$ entries are the anticlockwise curves and the final $\ell$ entries are the clockwise curves. Why is this important? It gives a way for boundary curve extraction to be done prior to using this package, if desired.

##Computing the XPHT
We similarly offer a function to compute the XPHT of a single image and a function to compute the XPHT of each image in a directory. However this time we are providing the extracted boundary curves. The differences are much the same as for extracting the boundaries, so we will only do this for a single image. So let's do that.

To compute the XPHT we need to compute the extended persistent homology in multiple directions. For symmetry reasons, we require an even number of directions and at least 2. If $2n$ directions are specified then these are computed so that the $2n$-th direction is along the positive $x$-axis. For our example, we will use 8 directions. In practice, you would typically want 32 or more.

```{r}
xphtA <- extendedPersistence(boundaryA, "A-courier-new", 8)
```

The extended persistence diagrams are stored in a list of length $2n$, where $2n$ is the number of directions used. The $k$-th entry holds the diagram for the image in the $k$-th direction.

```{r}
length(xphtA)
```

Let's take a closer look at a diagram as these are the objects that we want to work with! 

```{r}
class(xphtA[[1]])
names(xphtA[[1]])
xphtA[[1]]
```

Each individual diagram has the class `extendedPHT`. This is stored just a named list. A diagram has named entries:

* `Name` contains the value of `imgName` provided to `extendedPersistence`. For us, this was 'A-courier-new'.
* `Ord0` contains the non-essential classes of ordinary persistent homology where the birth vertex is a local minimum.
* `Rel1` contains the non-essential classes of ordinary persistent homology where the birth vertex is not a local minimum.
* `Ess0` contains the essential classes of ordinary persistent homology where the birth vertex is a local minimum.
* `Ess1` contains the essential classes of ordinary persistent homology where the birth vertex is not a local minimum.

More details on each of these can be found in [Turner, Robins, & Morgan](https://arxiv.org/abs/2208.14583).

It is entirely possible that some of these may be empty - and that's fine. While we're here, let's compute the XPHT for the letter **g** we loaded in.

```{r}
xphtg <- extendedPersistence(boundaryg, "g-courier-new", 8)
```

In the case we have a directory of of R data files containing the boundary curves of some images, we can use the `multiExtendedPersistence` function to handle these.

## Plotting Extended Persistence Diagrams
Computing the XPHT is great, but we really would like to see some of these diagrams. Thankfully we have a generic plot function to do just this. To plot an extended persistence diagram, we pass one of the diagrams in the list produced by `extendedPersistence` to the plot function. As these plots can vary wildly, you must specify a legend externally. To help with this, the function `getDefaultColours()` returns the default colours used to plot the extended persistence diagram.

```{r}
par(mfrow = c(1, 2))
plot(xphtA[[1]], main = "Extended Persistence of A\nin Direction pi/4")
legend("bottomright", legend = c("Ord0", "Rel1", "Ess0", "Ess1"),
       col = getDefaultColours(), pch = 15:18)
plot(xphtg[[1]], main = "Extended Persistence of g\nin Direction pi/4")
legend("topright", legend = c("Ord0", "Rel1", "Ess0", "Ess1"),
       col = getDefaultColours(), pch = 15:18)
```

Here, the `Ord0` and `Ess0` classes are plotted above the line $y=x$, whereas the `Rel1` and `Ess1` classes are plotted below this line.

Another useful plot we can use to visualise the extended persistent homology is the barcode. Rather than plotting points as $(birth,death)$ points in the plane, we plot horizontal line segments for each point which go from the birth time to the death time of that class. This is done by specifying `barcode=TRUE` in the plot function. In order to plot a legend in this case it is typically easier to use the `inset` argument in order to display the legend outside of the plot. This means we may need to adjust the margins of the plot regions.

```{r}
par(mfrow = c(2, 1), mar = c(5.1, 4.1, 4.1, 8.1), xpd = TRUE)
plot(xphtA[[1]], barcode = TRUE,
     main = "Extended Persistence Barcode of A\nin Direction pi/4")
legend("topright", inset = c(-0.3, 0),
       legend = c("Ord0", "Rel1", "Ess0", "Ess1"), lty = c(1, 1, 1, 1),
       col = getDefaultColours(), lwd = 2)
plot(xphtg[[1]], barcode = TRUE,
     main = "Extended Persistence Barcode of g\nin Direction pi/4")
legend("topright", inset = c(-0.3, 0),
       legend = c("Ord0", "Rel1", "Ess0", "Ess1"), lty = c(1, 1, 1, 1),
       col = getDefaultColours(), lwd = 2)
```

Both of these formats convey the same information. It's just a question of which one is easier for your purposes.

# Centring and Scaling Images
When comparing images we need to make sure comparing their persistence diagrams makes sense. There are two issues here:

* When we extract the boundary curves we assign coordinates based on their index in the matrix form of the image. This means that everything has positive coordinates. Depending on the image there might be a lot more background surrounding it meaning the coordinates we see may be vastly different.
* The images we compare may have wildly different sizes. This will primarily affect the lifetimes of the persistence classes we see, along with the issue of their position.

To counteract this we can centre and scale the images. Doing this to a whole image can be computationally expensive so instead we can do this to the XPHT of each image. Of these two operations, centring will nearly always need to be done and so we offer functionality to do this alone. Let's try it on the examples we plotted previously:

```{r}
centredA <- centreScaleDiagrams(xphtA, scale = FALSE)
centredg <- centreScaleDiagrams(xphtg, scale = FALSE)
par(mfrow = c(2, 1), mar = c(5.1, 4.1, 4.1, 8.1), xpd = TRUE)
plot(centredA[[1]], barcode = TRUE,
     main = "Centred Extended Persistence Barcode of A\nin Direction pi/4")
legend("topright", inset = c(-0.3, 0),
       legend = c("Ord0", "Rel1", "Ess0", "Ess1"), lty = c(1, 1, 1, 1),
       col = getDefaultColours(), lwd = 2)
plot(centredg[[1]], barcode = TRUE,
     main = "Centred Extended Persistence Barcode of g\nin Direction pi/4")
legend("topright", inset = c(-0.3, 0),
       legend = c("Ord0", "Rel1", "Ess0", "Ess1"), lty = c(1, 1, 1, 1),
       col = getDefaultColours(), lwd = 2)
```

Observe that the lifetimes are now centred around 0 rather than approximately 90.

For the example data set we have set the font size to be consistent amongst the images, however this is not a general feature of image data. Setting the argument `scale=TRUE` allows us to scale the images so that they are relatively consistently sized. This will, perhaps unsurprisingly, control the scale of the birth and death times that you will see. You can also specify a constant which controls the scaling, allowing the scaled version to be larger or smaller depending on what you want. As an example, we will set `scaleConstant=5`.

```{r}
scaledA <- centreScaleDiagrams(xphtA, scale = TRUE, scaleConstant = 5)
scaledg <- centreScaleDiagrams(xphtg, scale = TRUE, scaleConstant = 5)
par(mfrow = c(2, 1), mar = c(5.1, 4.1, 4.1, 8.1), xpd = TRUE)
plot(scaledA[[1]], barcode = TRUE, main = "Centred and Scaled Extended
     Persistence Barcode of A\nin Direction pi/4")
legend("topright", inset = c(-0.3, 0),
       legend = c("Ord0", "Rel1", "Ess0", "Ess1"), lty = c(1, 1, 1, 1),
       col = getDefaultColours(), lwd = 2)
plot(scaledg[[1]], barcode = TRUE, main = "Centred and Scaled Extended
     Persistence Barcode of g\nin Direction pi/4")
legend("topright", inset = c(-0.3, 0),
       legend = c("Ord0", "Rel1", "Ess0", "Ess1"), lty = c(1, 1, 1, 1),
       col = getDefaultColours(), lwd = 2)
```

Details on the centring and scaling algorithms can be found in [Turner, Mukherjee, & Boyer (2014)](https://doi.org/10.1093/imaiai/iau011).

# Computing Distances between Extended Persistence Diagrams
Our computation of the XPHT requires computing the extended persistent homology in finitely many directions. In order to compare how close two shapes are we need to compute the distance between their XPHTs. This is done entirely analogously to the method described in [Turner, Mukherjee, & Boyer (2014)](https://doi.org/10.1093/imaiai/iau011). We give a brief explanation here, but suggest any interested readers consult the paper as it is much more detailed and likely clearer.

## Light Details of Computing the $q$-Wasserstein Distance
In short, we compute the $q$-Wasserstein distance between two extended persistence diagrams by computing the $q$-Wasserstein distance between each of the four sub-diagrams (`Ord0`, `Rel1`, `Ess0`, `Ess1`), adding them, and finally averaging overall directions and taking the $q$-th root. In more detail, let $X$ and $Y$ be two binary images. Let $Ord_0(X,v)$ and $Ord_0(Y,v)$ be the `Ord0` subdiagram of the extended persistent homology in direction $v$ for each image.

* If both $Ord_0(X,v)$ and $Ord_0(Y,v)$ have no points, then the distance between them is $0$.
* If $Ord_0(X,v)$ has $n>0$ points and $Ord_0(Y,v)$ has no points, then we take the sum of the distance of each point in $Ord_0(X,v)$ to the diagonal $y=x$. This is similar if $Ord_0(X,v)$ has no points and $Ord_0(Y,v)$ has $n>0$ points.
* If both $Ord_0(X,v)$ and $Ord_0(Y,v)$ contain a non-zero number of points then we take the distance to be the minimum over all matchings of points (matching some to the diagonal $y=x$ when needed). This is achieved by using an implementation of the Hungarian algorithm.

This process is the same for each of the four subdiagrams. 

There are two options for computing this process depending on whether the initial images have been aligned relative to each other. Let $\{v_1,\dots,v_2n\}$ be the directions used to compute the XPHT.

* If the images $X$ and $Y$ are aligned, then we take the distance between their extended persistence diagrams in the same direction.
* If the images $X$ and $Y$ are unaligned, then we take the distance between we take the distance between the extended persistence diagram of $X$ in direction $v_i$ against each of the $2n$ extended persistence diagrams of $Y$ and take the distance as the minimum of all these.

## Computing the Aligned and Unaligned Distances
With the (light) details out the way we can get to doing some computing. It is important to note that we are computing the distance between different *objects* and so will need to compute multiple XPHTs. While we encourage the user to do this (using the `multiExtendedPersistence` function) we have provided the centred XPHT in 32 directions for a subset of the provided letter **A** and **g** images. We choose a subset as, given $n$ images, we must compute $n(n-1)/2$ distances (as the distance between an image and itself is 0) and this can take a while. 

Our first job is to load these in and store all diagrams in a single list. This can be achieved 

```{r}
fpathA <- system.file("extdata/xpht32A/", package = "XPHT")
fpathg <- system.file("extdata/xpht32g/", package = "XPHT")
diagramsA <- stackDiagrams(fpathA)
diagramsg <- stackDiagrams(fpathg)
```

For demonstration purposes we will compute both the aligned and unaligned distances for each set of objects. To do this we also need to specify the number of images (which is conveniently output from the `stackDiagrams` function). By default, we assume the objects are unaligned.

```{r}
distMatrixA.aligned <- computeDistanceMatrix(diagramsA, 13, q = 2,
                                             aligned = TRUE, verbose = FALSE)
distMatrixg.unaligned <- computeDistanceMatrix(diagramsg, 13, q = 2,
                                               verbose = FALSE)
```

We can quickly check what one of these matrices looks like:
```{r}
distMatrixA.aligned[1:6, 1:6]
```

From this small portion we can see what we expect - a symmetric matrix with 0s along the diagonal.

## Using Distance Matrices for Multidimensional Scaling
We close off this vignette with a toy example of using multidimensional scaling on the XPHT of the letter **g**s. We have provided a precomputed distance matrix of the centred (but not scaled) XPHTs for all 95 letter **g** images. For lowercase g's a key feature is whether it has one or two closed loops. This is referred to as having one or two storeys. We provide a text file labelling each letter **g** image appropriately.

Before we compute this, let's define a convenient plotting function.

```{r}
plot.mds <- function(x, labels, main = NULL,
                     colour = c("#E41A1C", "#377EB8", "#4DAF4A"),
                     legend.pos = "topleft", cex = 1.3, pch = 19,
                     cex.main = 1.5, cex.legend = 0.9, ...) {
  points.mds <- x$points

  limxy <- range(points.mds)
  limxy <- limxy + ((limxy[2] - limxy[1]) * 0.15) * c(-0.5, 0.5)

  par(mar = c(0.2, 0.8, 1.1, 0.8), ps = 10)
  plot(limxy, limxy, type = "n", axes = FALSE, frame = FALSE)
  rect(limxy[1], limxy[1], limxy[2], limxy[2], border = "#999999", lwd = 0.3)

  points(points.mds[, 1], points.mds[, 2], col = colour[as.integer(labels)],
         cex = cex, pch = pch)
  mtext(side = 3, main, cex = cex.main)

  labels.u <- unique(labels)
  legend.text <- as.character(labels.u)

  legend(legend.pos, legend = legend.text, inset = 0.03,
         col = colour[as.integer(labels.u)], bty = "n", pch = pch,
         cex = cex.legend)
}
```

We are now ready to compute the MDS using out distance matrix. This is done using the inbuilt `cmdscale` function.

```{r}
fpath.matrix <- system.file("extdata/distMatg.RDS", package = "XPHT")
fpath.labels <- system.file("extdata/storey.txt", package = "XPHT")
distMat <- readRDS(fpath.matrix)
labels <- factor(scan(fpath.labels, character(), quote = ""))

fonts.mds <- cmdscale(distMat, eig = TRUE, k = 2)
plot.mds(fonts.mds, labels = labels,
         main = "MDS of Letter g Images using 2-Wasserstein Distance")
```

For the most part our implementation of the XPHT has resulted in a successful clustering of the lowercase letter **g** depending on whether it has one or two storeys. One of the fonts used has uppercase letters when using lowercase and there was also one image which was fairly noisy. As an exercise to the user, we leave the problem of determining which image this was!
